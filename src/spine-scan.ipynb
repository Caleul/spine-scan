{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3eb3e39-098e-483c-9bb2-d5127a6bf8d7",
   "metadata": {},
   "source": [
    "# Instalação e importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ec8da3-3c51-4afc-99cd-949940be1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless numpy tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, regularizers, optimizers, callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8d1588-4b4f-48d2-a603-dc813b703855",
   "metadata": {},
   "source": [
    "**Atenção:** O aviso acima apenas informa que não foram encontrados drivers cuda e por conta disso será usada a CPU da máquina ao invés da GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28962c8a",
   "metadata": {},
   "source": [
    "# Coleta e processamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1ed72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_resized = cv2.resize(img, (224, 224))\n",
    "    img_normalized = img_resized / 255.0\n",
    "    return img_normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d6807d",
   "metadata": {},
   "source": [
    "## Balanceamento do DataSet\n",
    "Para evitar maior peso em um determinado tipo de dado, foi feito um balanceamento do dataset.\n",
    "\n",
    "Para isso, foi utilizado o método de reamostragem chamado de undersampling, no qual foi selecionado aleatoriamente os dados de uma classe e duplicado até que a quantidade de dados de cada classe se iguale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ad1f84-059e-439a-9177-d6eaa951629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = './dataset'\n",
    "balanced_dataset_dir = './balanced-dataset'\n",
    "\n",
    "classes = ['healthy', 'kyphosis', 'lordosis']\n",
    "\n",
    "os.makedirs(balanced_dataset_dir, exist_ok=True)\n",
    "\n",
    "image_counts = {}\n",
    "for cls in classes:\n",
    "    cls_path = os.path.join(dataset_dir, cls)\n",
    "    image_counts[cls] = len(os.listdir(cls_path))\n",
    "\n",
    "max_images = max(image_counts.values())\n",
    "new_image_counts = {}\n",
    "\n",
    "for cls in classes:\n",
    "    os.makedirs(os.path.join(balanced_dataset_dir, cls), exist_ok=True)\n",
    "    \n",
    "    images = os.listdir(os.path.join(dataset_dir, cls))\n",
    "    \n",
    "    for index, image in enumerate(images):\n",
    "        new_name = f\"{cls}_{index + 1:03d}.jpg\"\n",
    "        shutil.copy(os.path.join(dataset_dir, cls, image), \n",
    "                    os.path.join(balanced_dataset_dir, cls, new_name))\n",
    "    \n",
    "    new_image_counts[cls] = len(images)\n",
    "\n",
    "    current_count = new_image_counts[cls]\n",
    "    while current_count < max_images:\n",
    "        image_to_copy = random.choice(images)\n",
    "        \n",
    "        new_name = f\"{cls}_{current_count + 1:03d}.jpg\"\n",
    "        shutil.copy(os.path.join(dataset_dir, cls, image_to_copy),\n",
    "                    os.path.join(balanced_dataset_dir, cls, new_name))\n",
    "        \n",
    "        current_count += 1\n",
    "\n",
    "print(\"Dataset balanceado criado em:\", balanced_dataset_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e21c3d",
   "metadata": {},
   "source": [
    "### Criando CNN (rede neural convolucional)\n",
    "Essa função cria um modelo CNN que passa por algumas camadas convolucionais para extrair características das imagens, nas quais foram utilizados as funções:\n",
    "- ReLU \n",
    "\t- Função de ativação que permite que a rede neural aprenda padrões complexos\n",
    "- Pooling\n",
    "\t- Operação de amostragem usada em redes convolucionais para reduzir as dimensões e/ou tamanho da imagem ou das saídas das camadas convolucionais, porém, preservando suas características mais importantes\n",
    "- Normalização de Batch\n",
    "\t- Normalização de dados de entrada para que a rede neural possa aprender mais rapidamente\n",
    "- Softmax\n",
    "\t- Função de ativação que converte um vetor de valores reais em uma distribuição de probabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5430f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3_class_cnn(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.Conv2D(3, (1, 1), padding=\"same\")(inputs)\n",
    "    \n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    x = base_model(x)\n",
    "    \n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_2_class_cnn(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.Conv2D(3, (1, 1), padding=\"same\")(inputs)\n",
    "    \n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    x = base_model(x)\n",
    "    \n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "input_shape = (224, 224, 1)\n",
    "\n",
    "generalist_cnn_model = create_3_class_cnn(input_shape)\n",
    "lordosis_cnn_model = create_2_class_cnn(input_shape)\n",
    "kiphosis_cnn_model = create_2_class_cnn(input_shape)\n",
    "\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2439ed3e",
   "metadata": {},
   "source": [
    "## Gerador de alterações nas imagens\n",
    "\n",
    "Para melhorar a amplitude do treinamento, foi utilizado o gerador de alterações nas imagens, que trás alterações em rotação, deslocamento, zoom, brilho e direção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ce7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    brightness_range = [0.8, 1.2],\n",
    "    validation_split = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9885e959",
   "metadata": {},
   "source": [
    "# Pré-processamento dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generalist_classes = ['healthy', 'kyphosis', 'lordosis']\n",
    "\n",
    "generalist_train_generator = train_datagen.flow_from_directory(\n",
    "    './balanced-dataset',\n",
    "    target_size = (224, 224),\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 4,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'training'\n",
    ")\n",
    "\n",
    "generalist_validation_generator = train_datagen.flow_from_directory(\n",
    "    './balanced-dataset',\n",
    "    target_size = (224, 224),\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 4,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'validation'\n",
    ")\n",
    "\n",
    "generalist_cnn_model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd613387",
   "metadata": {},
   "outputs": [],
   "source": [
    "lordosis_classes = ['healthy', 'lordosis']\n",
    "\n",
    "lordosis_train_generator = train_datagen.flow_from_directory(\n",
    "    './balanced-dataset',\n",
    "    target_size = (224, 224),\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 4,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'training',\n",
    "    classes = lordosis_classes\n",
    ")\n",
    "\n",
    "lordosis_validation_generator = train_datagen.flow_from_directory(\n",
    "    './balanced-dataset',\n",
    "    target_size = (224, 224),\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 4,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'validation',\n",
    "    classes = lordosis_classes\n",
    ")\n",
    "\n",
    "lordosis_cnn_model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "kiphosis_classes = ['healthy', 'kyphosis']\n",
    "\n",
    "kiphosis_train_generator = train_datagen.flow_from_directory(\n",
    "    './balanced-dataset',\n",
    "    target_size = (224, 224),\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 4,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'training',\n",
    "    classes = kiphosis_classes\n",
    ")\n",
    "\n",
    "kiphosis_validation_generator = train_datagen.flow_from_directory(\n",
    "    './balanced-dataset',\n",
    "    target_size = (224, 224),\n",
    "    color_mode = 'grayscale',\n",
    "    batch_size = 4,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'validation',\n",
    "    classes = kiphosis_classes\n",
    ")\n",
    "\n",
    "kiphosis_cnn_model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f06ed8b",
   "metadata": {},
   "source": [
    "# Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b34fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generalist_history = generalist_cnn_model.fit(\n",
    "    generalist_train_generator,\n",
    "    validation_data = generalist_validation_generator,\n",
    "    epochs = 30,\n",
    "    callbacks = [lr_scheduler]\n",
    ")\n",
    "\n",
    "lordosis_history = lordosis_cnn_model.fit(\n",
    "    lordosis_train_generator,\n",
    "    validation_data = lordosis_validation_generator,\n",
    "    epochs = 30,\n",
    "    callbacks = [lr_scheduler]\n",
    ")\n",
    "\n",
    "kiphosis_history = kiphosis_cnn_model.fit(\n",
    "    kiphosis_train_generator,\n",
    "    validation_data = kiphosis_validation_generator,\n",
    "    epochs = 30,\n",
    "    callbacks = [lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8b8cf4-89af-4aa1-bc2b-c4f160b02f93",
   "metadata": {},
   "source": [
    "## Porque resultados sempre são diferentes:\n",
    "- Ao inicializar o modelo os pesos da rede neural são inicializados de forma aleatória, e como o processo de otimização do modelo começa a partir de diferentes pontos cada execução pode levar a resultados diferentes, por isso, cada vez que o código for executado os resultados não serão exatamente os mesmos, mas aproximados.\n",
    "- Image Augmentation: técnicas de rotação, deslocamento, zoom e etc. aplicadas na imagem para criar novas variações para realizar o treinamento do modelo, sendo também um processo aleatório.\n",
    "- Shuffling: Durante o treinamento, os dados de treino são embaralhados a cada época. Isso garante que o modelo não aprenda de forma dependente da ordem dos exemplos, mas também pode fazer com que os resultados variem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5bfd3e",
   "metadata": {},
   "source": [
    "# Validação dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "generalist_val_loss, generalist_val_acc = generalist_cnn_model.evaluate(generalist_validation_generator)\n",
    "lordosis_val_loss, lordosis_val_acc = lordosis_cnn_model.evaluate(lordosis_validation_generator)\n",
    "kiphosis_val_loss, kiphosis_val_acc = kiphosis_cnn_model.evaluate(kiphosis_validation_generator)\n",
    "\n",
    "print(f\"Validação modelo generalista - Loss: {generalist_val_loss}, Acurácia: {generalist_val_acc}\")\n",
    "print(f\"Validação modelo de lordose - Loss: {lordosis_val_loss}, Acurácia: {lordosis_val_acc}\")\n",
    "print(f\"Validação modelo de cifose - Loss: {kiphosis_val_loss}, Acurácia: {kiphosis_val_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2017a",
   "metadata": {},
   "source": [
    "# Função de predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ef124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model):\n",
    "    img = preprocess_image(image_path)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    prediction = model.predict(img)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    return predicted_class, prediction\n",
    "\n",
    "generalist_predicted_class, generalist_result = predict_image('./test-data/001.jpg', generalist_cnn_model)\n",
    "lordosis_predicted_class, lordosis_result = predict_image('./test-data/001.jpg', lordosis_cnn_model)\n",
    "kiphosis_predicted_class, kiphosis_result = predict_image('./test-data/001.jpg', kiphosis_cnn_model)\n",
    "\n",
    "print(f'Predição (modelo generalista): {generalist_result}')\n",
    "print(f'Classe prevista (modelo generalista): {generalist_classes[generalist_predicted_class]}')\n",
    "\n",
    "print(f'Predição (modelo de lordose): {lordosis_result}')\n",
    "print(f'Classe prevista (modelo de lordose): {lordosis_classes[lordosis_predicted_class]}')\n",
    "\n",
    "print(f'Predição (modelo de cifose): {kiphosis_result}')\n",
    "print(f'Classe prevista (modelo de cifose): {kiphosis_classes[kiphosis_predicted_class]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
